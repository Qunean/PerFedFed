import numpy as np
import torch
from torch.ao.nn.quantized.functional import threshold

from src.utils.tools import vectorize


def load_model_weight_diff(net, weight_diff, global_weight):
    """
    load rule: w_t + clipped(w^{local}_t - w_t)
    """
    listed_global_weight = list(global_weight.parameters())
    index_bias = 0
    for p_index, p in enumerate(net.parameters()):
        p.data =  weight_diff[index_bias:index_bias+p.numel()].view(p.size()) + listed_global_weight[p_index]
        index_bias += p.numel()


class Defense:
    def __init__(self, *args, **kwargs):
        self.hyper_params = None

    def exec(self, client_model, *args, **kwargs):
        raise NotImplementedError()

    def aggregate(self,client_package):
        pass

    def evaluate_detection(self,clients_pred_result=None,clients_malicious_label=None):
        """
        è®¡ç®— DACCã€FPR å’Œ FNR æŒ‡æ ‡ã€‚
        """
        # å°†æ•°æ®è½¬æ¢ä¸º NumPy æ•°ç»„ï¼Œç¡®ä¿å¯ä»¥è¿›è¡Œå‘é‡åŒ–è®¡ç®—
        pred = np.array(clients_pred_result)
        label = np.array(clients_malicious_label)

        # -------------------------------1. è®¡ç®— DACC-------------------------------
        correct_predictions = (pred == label).sum()
        total_clients = len(label)
        DACC = correct_predictions / total_clients if total_clients > 0 else 0.0

        # -------------------------------2. è®¡ç®— FPR-------------------------------
        benign_clients = (label == 0)  # çœŸå®è‰¯æ€§å®¢æˆ·ç«¯
        false_positives = ((pred == 1) & (label == 0)).sum()  # è¢«é”™è¯¯æ ‡è®°ä¸ºæ¶æ„çš„è‰¯æ€§å®¢æˆ·ç«¯
        total_benign_clients = benign_clients.sum()
        FPR = false_positives / total_benign_clients if total_benign_clients > 0 else 0.0

        # -------------------------------3. è®¡ç®— FNR-------------------------------
        malicious_clients = (label == 1)  # çœŸå®æ¶æ„å®¢æˆ·ç«¯
        false_negatives = ((pred == 0) & (label == 1)).sum()  # è¢«é”™è¯¯æ ‡è®°ä¸ºè‰¯æ€§çš„æ¶æ„å®¢æˆ·ç«¯
        total_malicious_clients = malicious_clients.sum()
        FNR = false_negatives / total_malicious_clients if total_malicious_clients > 0 else 0.0

        # æ‰“å°ç»“æœ
        self.logger.log("ğŸ•µï¸ æ£€æµ‹ç»“æœï¼š")
        self.logger.log(f"DACC (æ£€æµ‹å‡†ç¡®ç‡): {DACC:.4f}")
        self.logger.log(f"FPR (å‡é˜³æ€§ç‡): {FPR:.4f}")
        self.logger.log(f"FNR (å‡é˜´æ€§ç‡): {FNR:.4f}")

        return {
            "DACC": DACC,
            "FPR": FPR,
            "FNR": FNR
        }


# only apply for fedavg
# WeightDiffClippingDefense çš„ç›®çš„æ˜¯é€šè¿‡è£å‰ªå®¢æˆ·ç«¯æ¨¡å‹å‚æ•°ä¸å…¨å±€æ¨¡å‹å‚æ•°çš„å·®å¼‚
# é™åˆ¶æ¯ä¸ªå®¢æˆ·ç«¯å¯¹å…¨å±€æ¨¡å‹æ›´æ–°çš„å½±å“ï¼Œä»è€Œå¢å¼ºè”é‚¦å­¦ä¹ çš„å®‰å…¨æ€§ã€‚è¿™ç§æ–¹æ³•é€šå¸¸ç”¨äºå¯¹æŠ—åé—¨æ”»å‡»æˆ–å¼‚å¸¸å®¢æˆ·ç«¯æ›´æ–°ã€‚
class WeightDiffClippingDefense(Defense):
    def __init__(self, norm_bound, *args, **kwargs):
        """
        åˆå§‹åŒ–æƒé‡å·®å¼‚è£å‰ªé˜²å¾¡å™¨
        :param norm_bound: æƒé‡å·®å¼‚çš„è£å‰ªé˜ˆå€¼
        """
        self.norm_bound = norm_bound

    def exec(self, client_packages, global_model_params, *args, **kwargs):
        """
        å¯¹æ¯ä¸ªå®¢æˆ·ç«¯æ¨¡å‹çš„æƒé‡è¿›è¡Œè£å‰ª
        :param client_packages: åŒ…å«æ‰€æœ‰å®¢æˆ·ç«¯æ¨¡å‹å’Œæ•°æ®çš„å­—å…¸
        :param global_model_params: å…¨å±€æ¨¡å‹å‚æ•°å­—å…¸
        :return: ä¿®æ”¹åçš„ client_packages
        """
        print("Starting defense process...")

        for client_id, client_data in client_packages.items():
            # è·å–å®¢æˆ·ç«¯æ¨¡å‹å‚æ•°
            client_regular_params = client_data["regular_model_params"]

            # å°†æ¨¡å‹å‚æ•°å‘é‡åŒ–
            vectorized_client_params = vectorize(client_regular_params)
            vectorized_global_params = vectorize(global_model_params)
            assert(len(vectorized_client_params) == len(vectorized_global_params))
            # è®¡ç®—æƒé‡å·®å¼‚
            vectorized_diff = vectorized_client_params - vectorized_global_params
            weight_diff_norm = torch.norm(vectorized_diff).item()

            # è£å‰ªæƒé‡å·®å¼‚
            clipped_diff = vectorized_diff / max(1, weight_diff_norm / self.norm_bound)

            # æ›´æ–°å®¢æˆ·ç«¯æ¨¡å‹å‚æ•°
            idx = 0
            for name, client_param in client_regular_params.items():
                # è·å–å½“å‰å‚æ•°çš„å…ƒç´ æ•°
                num_elements = client_param.numel()
                # ä»è£å‰ªåçš„å·®å¼‚ä¸­å–å‡ºå¯¹åº”éƒ¨åˆ†
                diff = clipped_diff[idx:idx + num_elements].view_as(client_param)
                # æ›´æ–°å‚æ•°å€¼
                client_param.copy_(global_model_params[name] + diff)
                # æ›´æ–°ç´¢å¼•
                idx += num_elements

        print("Defense process completed.")

class PerFedFedDefense(Defense):
    def __init__(self,bound, *args, **kwargs):
        self.bound = bound
        self.clients_pred_result = kwargs.get("clients_pred_result", None)
        self.clients_malicious_label = kwargs.get("clients_malicious_label", None)
        self.logger = kwargs.get("logger", None)

    def exec(self, client_packages, global_VAE_params, *args, **kwargs):
        param_diffs = []
        for client_id, client_data in client_packages.items():
            # è·å–å®¢æˆ·ç«¯æ¨¡å‹å‚æ•°
            client_regular_params = client_data["VAE_regular_params"]

            # å°†æ¨¡å‹å‚æ•°å‘é‡åŒ–
            vectorized_client_params = vectorize(client_regular_params)
            vectorized_global_params = vectorize(global_VAE_params)
            assert (len(vectorized_client_params) == len(vectorized_global_params))
            # è®¡ç®—æƒé‡å·®å¼‚
            vectorized_diff = vectorized_client_params - vectorized_global_params
            weight_diff_norm = torch.norm(vectorized_diff).item()
            param_diffs.append(weight_diff_norm)
        param_diffs = torch.tensor(param_diffs, dtype=torch.float)
        mean_diff = param_diffs.mean()
        std_diff = param_diffs.std()

        threshold = mean_diff+ self.bound * std_diff

        mask = param_diffs <= threshold

        valid_client_ids = [cid for i, cid in enumerate(client_packages.keys()) if mask[i]]
        invalid_client_ids = [cid for i, cid in enumerate(client_packages.keys()) if not mask[i]]
        self.logger.log(f"âš ï¸ æ£€æµ‹åˆ° {len(invalid_client_ids)} ä¸ªå¼‚å¸¸å®¢æˆ·ç«¯: {invalid_client_ids}")

        for i, cid in enumerate(client_packages.keys()):
            if mask[i]:
                # å½“å‰è½®æ¬¡æ£€æµ‹ä¸ºè‰¯æ€§å®¢æˆ·ç«¯ -> é‡ç½®ä¸º0
                self.clients_pred_result[cid] = 0
            else:
                # å½“å‰è½®æ¬¡æ£€æµ‹ä¸ºæ¶æ„å®¢æˆ·ç«¯ -> ä¿æŒæˆ–è®¾ç½®ä¸º1
                self.clients_pred_result[cid] = 1

                # æ‰“å°å®¢æˆ·ç«¯æ¶æ„çŠ¶æ€
        self.logger.log(f"ğŸ›¡ï¸ å®¢æˆ·ç«¯çŠ¶æ€æ ‡è®° (æœ€æ–°æ£€æµ‹ç»“æœ): {self.clients_pred_result}")
        self.evaluate_detection(self.clients_pred_result,self.clients_malicious_label)

        valid_clients_package = {
            cid: client_packages[cid] for cid in valid_client_ids
        }
        return valid_clients_package



class FLdetectorDefense(Defense):
    def __init__(self,bound, *args, **kwargs):
        pass




